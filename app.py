# app.py
from dotenv import load_dotenv
load_dotenv()

import streamlit as st
import os
import time
import random
import json
import logging
from google import genai
from google.genai.errors import APIError
from google.genai.types import GenerateContentConfig

# --- C·∫•u h√¨nh trang ---
st.set_page_config(page_title="Streamlit AI Chatbot ‚ú®", layout="wide")

# --- C·∫•u h√¨nh Logging ---
logging.basicConfig(
    filename="gemini_errors.log",
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s"
)

# --- L·∫•y API key t·ª´ m√¥i tr∆∞·ªùng ---
API_KEY = os.getenv("GEMINI_API_KEY")

# --- Kh·ªüi t·∫°o client Gemini ---
client = None
if API_KEY:
    try:
        client = genai.Client(api_key=API_KEY)
    except Exception as e:
        st.error(f"‚ö†Ô∏è L·ªói kh·ªüi t·∫°o Gemini Client: {e}")
else:
    client = None

MODEL_NAME = "gemini-2.5-flash"
SYSTEM_INSTRUCTION = """B·∫°n l√† 'StreamlitBot' ‚Äî m·ªôt tr·ª£ l√Ω AI th√¢n thi·ªán v√† chuy√™n nghi·ªáp, tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát. 
H√£y ng·∫Øn g·ªçn, t·ª± nhi√™n, v√† n·∫øu kh√¥ng ch·∫Øc ch·∫Øn, h√£y n√≥i 'T√¥i ch∆∞a r√µ l·∫Øm v·ªÅ ƒëi·ªÅu ƒë√≥'."""

# --- ƒê∆∞·ªùng d·∫´n file l∆∞u h·ªôi tho·∫°i ---
HISTORY_FILE = "chat_history.json"


# --- H√†m x·ª≠ l√Ω l∆∞u/ƒë·ªçc JSON ---
def load_history():
    """ƒê·ªçc file JSON ch·ª©a h·ªôi tho·∫°i c≈©."""
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                return data
        except Exception:
            return []
    return []

def save_history(messages):
    """Ghi to√†n b·ªô l·ªãch s·ª≠ h·ªôi tho·∫°i ra file JSON."""
    try:
        with open(HISTORY_FILE, "w", encoding="utf-8") as f:
            json.dump(messages, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logging.error(f"L·ªói l∆∞u h·ªôi tho·∫°i JSON: {e}")

def clear_history():
    """X√≥a file l·ªãch s·ª≠ v√† session."""
    if os.path.exists(HISTORY_FILE):
        os.remove(HISTORY_FILE)
    st.session_state.clear()
    st.rerun()


# --- H√†m g·ªçi API Gemini v·ªõi retry ---
def get_gemini_response(prompt_history, current_user_prompt,
                        model_name=MODEL_NAME,
                        system_instruction=SYSTEM_INSTRUCTION,
                        max_retries=5, base_delay=1.0):
    if not client:
        return "‚ö†Ô∏è Ch∆∞a c√≥ API Key. Vui l√≤ng thi·∫øt l·∫≠p bi·∫øn m√¥i tr∆∞·ªùng GEMINI_API_KEY."

    contents = []
    for msg in prompt_history:
        role_map = {"user": "user", "assistant": "model"}
        contents.append({
            "role": role_map[msg["role"]],
            "parts": [{"text": msg["content"]}]
        })
    contents.append({"role": "user", "parts": [{"text": current_user_prompt}]})

    config = GenerateContentConfig(system_instruction=system_instruction)

    attempt = 0
    while attempt < max_retries:
        try:
            attempt += 1
            response = client.models.generate_content(
                model=model_name,
                contents=contents,
                config=config,
            )
            return response.text  # ‚úÖ Th√†nh c√¥ng

        except APIError as e:
            logging.warning(f"Attempt {attempt}/{max_retries} - APIError: {e}")
            if attempt >= max_retries:
                logging.error(f"Max retries reached. APIError final: {e}")
                break
            delay = base_delay * (2 ** (attempt - 1))
            jitter = random.uniform(0, 0.5 * delay)
            time.sleep(delay + jitter)
            continue

        except Exception as e:
            logging.exception(f"Attempt {attempt}/{max_retries} - Unexpected error: {e}")
            if attempt >= max_retries:
                break
            delay = base_delay * (2 ** (attempt - 1))
            jitter = random.uniform(0, 0.5 * delay)
            time.sleep(delay + jitter)
            continue

    fallback = (
        "‚ö†Ô∏è Hi·ªán t·∫°i kh√¥ng th·ªÉ k·∫øt n·ªëi t·ªõi Gemini (m√¥ h√¨nh c√≥ th·ªÉ ƒëang qu√° t·∫£i). "
        "Vui l√≤ng th·ª≠ l·∫°i sau v√†i ph√∫t.\n\n"
        "üëâ G·ª£i √Ω: Nh·∫•n **Th·ª≠ l·∫°i**, ho·∫∑c ki·ªÉm tra l·∫°i API Key / quota t√†i kho·∫£n."
    )
    return fallback


# --- Hi·ªÉn th·ªã tin nh·∫Øn ƒë·∫πp ---
def render_message(role, content):
    avatar = "ü§ñ" if role == "assistant" else "üßç‚Äç‚ôÇÔ∏è"
    bg_color = "#F0F2F6" if role == "assistant" else "#DCF8C6"
    align = "left" if role == "assistant" else "right"
    st.markdown(
        f"""
        <div style='display: flex; justify-content: {align}; margin: 8px 0;'>
            <div style='background-color:{bg_color}; padding:10px 15px; border-radius:15px; max-width:70%;'>
                <b>{avatar} {'StreamlitBot' if role == 'assistant' else 'B·∫°n'}:</b><br>{content}
            </div>
        </div>
        """,
        unsafe_allow_html=True
    )


# --- Giao di·ªán ch√≠nh ---
def main():
    col1, col2 = st.columns([1, 2])

    with col1:
        st.image("https://cdn-icons-png.flaticon.com/512/4712/4712100.png", width=160)
        st.markdown("### ü§ñ StreamlitBot")
        st.write("Tr·ª£ l√Ω AI powered by **Gemini 2.5 Flash**.")
        st.write("H·ªèi t√¥i b·∫•t c·ª© ƒëi·ªÅu g√¨ b·∫±ng ti·∫øng Vi·ªát üí¨")
        st.markdown("---")
        if st.button("üóëÔ∏è X√≥a l·ªãch s·ª≠ chat"):
            clear_history()

    with col2:
        st.title("üí≠ Chat c√πng AI")
        if not client:
            st.warning("‚ö†Ô∏è Vui l√≤ng thi·∫øt l·∫≠p bi·∫øn m√¥i tr∆∞·ªùng GEMINI_API_KEY ƒë·ªÉ ·ª©ng d·ª•ng ho·∫°t ƒë·ªông.")
            return

        # --- Kh·ªüi t·∫°o ho·∫∑c n·∫°p l·∫°i l·ªãch s·ª≠ ---
        if "messages" not in st.session_state:
            saved_msgs = load_history()
            if saved_msgs:
                st.session_state["messages"] = saved_msgs
            else:
                st.session_state["messages"] = [
                    {"role": "assistant", "content": "Xin ch√†o! T√¥i l√† StreamlitBot üòä. T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n h√¥m nay?"}
                ]

        # --- Hi·ªÉn th·ªã h·ªôi tho·∫°i ---
        for msg in st.session_state.messages:
            render_message(msg["role"], msg["content"])

        # --- Nh·∫≠p c√¢u h·ªèi ---
        if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            render_message("user", prompt)

            with st.spinner("StreamlitBot ƒëang suy nghƒ©..."):
                history = st.session_state.messages[:-1]
                response = get_gemini_response(history, prompt)

            # --- N·∫øu l·ªói ---
            if response.startswith("‚ö†Ô∏è"):
                st.error(response)
                if st.button("üîÅ Th·ª≠ l·∫°i"):
                    with st.spinner("ƒêang th·ª≠ l·∫°i..."):
                        response2 = get_gemini_response(history, prompt)
                    render_message("assistant", response2)
                    st.session_state.messages.append({"role": "assistant", "content": response2})
                    save_history(st.session_state.messages)
            else:
                render_message("assistant", response)
                st.session_state.messages.append({"role": "assistant", "content": response})

            # --- L∆∞u l·∫°i h·ªôi tho·∫°i m·ªõi ---
            save_history(st.session_state.messages)


if __name__ == "__main__":
    main()
